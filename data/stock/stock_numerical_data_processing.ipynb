{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Searc\\OneDrive\\CSE\\CS7643\\Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Searc\\AppData\\Local\\Temp\\ipykernel_15572\\288586424.py:24: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['Date'] = pd.to_datetime(df['Date'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def calculate_metrics(input_csv: str, output_csv: str, scaler_pkl: str, eps: float = 10.0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_csv (str): Path to input \n",
    "        output_csv (str): Path to output CSV.\n",
    "        scaler_pkl (str): Path to pickles.\n",
    "        eps (float): for P/E ratio calculation\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "    df = df.iloc[:, 1:]  \n",
    "\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values(['Date']) \n",
    "    df['Adjusted Close'] = df['Close'] + df.get('Dividends', 0)\n",
    "    df['Market Cap'] = df['SharesOutstanding'] * df['Volume']\n",
    "    df['Volatility'] = df['Open'].rolling(window=7).std()\n",
    "\n",
    "    #RSI\n",
    "    delta = df['Close'].diff()\n",
    "    gain = np.where(delta > 0, delta, 0)\n",
    "    loss = np.where(delta < 0, -delta, 0)\n",
    "    avg_gain = pd.Series(gain).rolling(window=14).mean()\n",
    "    avg_loss = pd.Series(loss).rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))  \n",
    "\n",
    "    #P/E\n",
    "    df['P/E Ratio'] = df['Close'] / eps \n",
    "\n",
    "    #Capped Percent Change\n",
    "    def compute_percent_change(col):\n",
    "        pct_change = df[col].pct_change()\n",
    "        pct_change = pct_change.clip(-1, 1)  \n",
    "        pct_change[df[col].shift(1) == 0] = 1.0  \n",
    "        return pct_change\n",
    "\n",
    "    df['% Change Adj Close'] = compute_percent_change('Adjusted Close')\n",
    "    df['% Change Open'] = compute_percent_change('Open')\n",
    "    df['% Change Volume'] = compute_percent_change('Volume')\n",
    "    df['% Change Market Cap'] = compute_percent_change('Market Cap')\n",
    "    df['% Change Volatility'] = compute_percent_change('Volatility')\n",
    "    df['% Change RSI'] = compute_percent_change('RSI')\n",
    "\n",
    "    #Log Transform\n",
    "    def log_transform(col):\n",
    "        return np.log(df[col].replace(0, np.nan))\n",
    "\n",
    "    df['Log Open'] = log_transform('Open')\n",
    "    df['Log Adjusted Close'] = log_transform('Adjusted Close')\n",
    "    df['Log Volume'] = log_transform('Volume')\n",
    "    df['Log Market Cap'] = log_transform('Market Cap')\n",
    "\n",
    "    df = df.drop(columns=['Open', 'Adjusted Close', 'Volume', 'Market Cap', 'High', 'Low', 'Close', \n",
    "                          'Dividends', 'Stock Splits'])\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    feature_columns = [\n",
    "        'Log Open', 'Log Adjusted Close', 'Log Volume', 'Log Market Cap',\n",
    "        'Volatility', 'RSI', 'P/E Ratio',\n",
    "        '% Change Adj Close', '% Change Open', '% Change Volume', '% Change Market Cap',\n",
    "        '% Change Volatility', '% Change RSI'\n",
    "    ]\n",
    "\n",
    "    scalers = {}\n",
    "    for feature in feature_columns:\n",
    "        scaler = StandardScaler()\n",
    "        reshaped_data = df[feature].dropna().values.reshape(-1, 1)\n",
    "        scaler.fit(reshaped_data)\n",
    "        scalers[feature] = scaler\n",
    "\n",
    "    with open(scaler_pkl, 'wb') as f:\n",
    "        pickle.dump(scalers, f)\n",
    "\n",
    "#Testing\n",
    "calculate_metrics(\"scraped_data/A_numerical_features.csv\", \"processed/A_numerical_features_output.csv\", \"scalers.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "input_folder = \"scraped_data/\"\n",
    "output_folder = \"processed/\"\n",
    "pkl_folder = \"pkl/\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(pkl_folder, exist_ok=True)\n",
    "\n",
    "#All files\n",
    "file_list = glob.glob(os.path.join(input_folder, \"*.*\"))\n",
    "file_list = [f for f in file_list if f.endswith(('.csv', '.xlsx', '.xls'))] \n",
    "\n",
    "print(f\"{len(file_list)} files\")\n",
    "\n",
    "#Data Processing\n",
    "for file_path in file_list:\n",
    "    file_name = os.path.basename(file_path) \n",
    "    base_name, ext = os.path.splitext(file_name) \n",
    "    output_csv = os.path.join(output_folder, f\"{base_name}_processed.csv\")\n",
    "    scaler_pkl = os.path.join(pkl_folder, f\"{base_name}.pkl\")\n",
    "\n",
    "    try:\n",
    "        if ext in ['.xlsx', '.xls']:\n",
    "            df = pd.read_excel(file_path)\n",
    "            temp_csv = os.path.join(input_folder, f\"{base_name}.csv\")\n",
    "            df.to_csv(temp_csv, index=False)\n",
    "            file_path = temp_csv \n",
    "\n",
    "        calculate_metrics(file_path, output_csv, scaler_pkl)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "print(\"Batch processing complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS7643",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
